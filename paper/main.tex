\documentclass{article}

\PassOptionsToPackage{numbers}{natbib}
\usepackage[preprint]{neurips_2022}

\usepackage{times}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{faktor}
\usepackage{hhline}
\let\proof\relax
\let\endproof\relax
\usepackage{thm-restate}
\newcommand{\numset}[1]{{\\mathbb #1}}
\usepackage{tikz}
\usepackage{mathtools, stmaryrd}
\usepackage{tocloft}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\usepackage[algo2e, algoruled, boxed, vlined]{algorithm2e}
\usepackage{algorithm}
\usepackage{algpseudocode}

\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}

\usepackage[noabbrev]{cleveref}


\title{Optimal first-order methods for convex functions \\ with a quadratic upper bound}


\author{
    Baptiste Goujaud\\
    CMAP, École Polytechnique, \\ Institut Polytechnique de Paris \\
    \texttt{baptiste.goujaud@polytechnique.edu}
    \And
    Adrien Taylor \\
    INRIA, École Normale Supérieure, \\ CNRS, PSL Research University, Paris \\
    \texttt{adrien.taylor@inria.fr}
    \And
    Aymeric Dieuleveut \\
    CMAP, École Polytechnique, \\ Institut Polytechnique de Paris \\ \texttt{aymeric.dieuleveut@polytechnique.edu}
}


\newtheorem{Th}{Theorem}[section]
\newtheorem{Lemma}[Th]{Lemma}
\newtheorem{Cor}[Th]{Corollary}
\newtheorem{Prop}[Th]{Proposition}

\newtheorem{Def}[Th]{Definition}
\newtheorem{Assump}[Th]{Assumption}
\newtheorem{Not}[Th]{Notation}
\newtheorem{Conj}[Th]{Conjecture}
\newtheorem{Rem}[Th]{Remark}
\newtheorem{?}[Th]{Problem}
\newtheorem{Ex}[Th]{Example}

\def\SC{\operatorname{SC}}
\def\EB{\operatorname{EB}}
\def\RSI{\operatorname{RSI}}
\def\PL{\operatorname{PL}}
\def\QG{\operatorname{QG}}
\def\RG{\operatorname{RG}}


\usepackage{amssymb}
\usepackage{pifont}
\newcommand{\cmark}{\textcolor{green!50!black}{\checkmark}}
\newcommand{\xmark}{\textcolor{red!50!black}{\times}}

\usepackage{float}
\usepackage{wrapfig}

\newcommand{\R}{\mathbb{R}}
\newcommand{\fs}{f_{\star}}

\begin{document}

\addtocontents{toc}{\protect\setcounter{tocdepth}{0}}

\maketitle

\input{core}


\begin{ack}
    The work of B. Goujaud and A. Dieuleveut is partially supported by ANR-19-CHIA-0002-01/chaire SCAI, and Hi!Paris.
    A. Taylor acknowledges support from the European Research Council (grant SEQUOIA 724063).
    This work was partly funded by the French government under management
    of Agence Nationale de la Recherche as part of the ``Investissements d’avenir'' program,
    reference ANR-19-P3IA-0001 (PRAIRIE 3IA Institute).
\end{ack}

\bibliographystyle{plainnat}
\bibliography{references}

\clearpage
\appendix

    \section*{Organisation of the appendix}
    
        This appendix contains the proofs of the theorems stated in the main core of the paper.
        We also state a conjecture and bring some evidence about its statement.
        This appendix also contains discussions and extended results.
        
        Appendix~\ref{apx:subgrad} details the results on the subgradient method.
        Appendix~\ref{apx:gd_proof_th1_upper_bound} contains the proof of \Cref{thm:gd_average},
        Appendix~\ref{apx:gd_lower_bound} contains the proof of \Cref{thm:non_convergence_gd}
        and Appendix~\ref{apx:gd_conjecture} contains a conjecture that does not appear in the main core of the paper.
        This appendix also contains some evidence supporting this conjecture.
        
        Appendix~\ref{apx:lower_bound} contains the proofs for lower bounds on the class $\QG^+$ convex.
        Appendix~\ref{apx:lower_bound_1} contains the proofs of \Cref{thm:general_lower_bound}
        stating the lower bound under the classical assumption
        that the difference between the iterates lies into the span of observed gradients.
        Appendix~\ref{apx:lower_bound_2} extends the latter results without the aforementioned assumption.
        
        Appendix~\ref{apx:main_result} contains the proof of Theorem~\ref{thm:main},
        the main result of the paper, stating that all first order algorithm verifying a given identity,
        also enjoys an upper bound guarantee.
        
        Appendix~\ref{apx:tab} contains the proofs of all the claims that figure in \Cref{tab:optimality_summary}
        that are not already made elsewhere in this work or in others.
        
        Appendix~\ref{apx:interpolation_conditions} contains the proof of \Cref{thm:interp},
        essential to use the PEP framework.
        
        Appendix~\ref{apx:upper_assumption} contains all the proofs
        and discussions related to the extended class of the $\RG^+$ convex functions
        
        Finally, Appendix~\ref{apx:restart} contains linear convergence result
        under an additional assumption similar to the classical quadratic growth assumption.
        This result is not presented in the main core in the paper,
        since it is a bit out of the scope of the main message.
        However, we thought it was worth mentioning it here.
    
    \hypersetup{linkcolor = black}
    \setlength\cftparskip{2pt}
    \setlength\cftbeforesecskip{2pt}
    \setlength\cftaftertoctitleskip{3pt}
    \addtocontents{toc}{\protect\setcounter{tocdepth}{2}}
    \setcounter{tocdepth}{1}
    \tableofcontents
    \hypersetup{linkcolor=blue}
    
    \input{appendix}

\end{document}
